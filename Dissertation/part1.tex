\chapter{Метод стохастического моделирования} \label{chapt1}

\section{Обзор метода стохастического моделирования Гаусса} \label{sect1_1}
Наиболее часто применения метода стохастического Гауссова моделирования можно найти в геофизических задачах для проведения интерполяции некоторых величин в межскважинном пространстве\cite[с.~33]{chung2019supplement}. Практика применения данного метода исходит из того факта, что большинство физических величин, которые простым или доступным способом могут быть измерены, не могут дать вполне четкой картины о распределении косвенно зависящих параметров. Поводом для этого может служить например небольшой набор исходных данных, сильная пространственная разреженность измерений. Интерполяция измеренных данных на протяжении интересующей области, в следствии выше сказанного, играет важную роль в процессе освоения нефтяных пластов, если касаться одного из возможных применений рассматриваемого метода. 

В общем случае имеется достаточно большой набор методов, с помощью которых можно провести интерполяцию данных, помимо упомянутого метода стохастического моделирования, это, например, методы линейной интерполяции, полиномиальная интерполяция (Лагранжевы многочлены). Близко к полиномиальным методам интерполяции можно отнести сплайн-функции и их частный случай, довольно распространённые кубические сплайны. Примерами, относящимися к многомерной интерполяции могут служить: билинейная интерполяция, бикубическая интерполяция.

Имеется достаточной большой выбор разнородных методов интерполяции, но из них выделяется рассматриваемый в данной главе метод интерполяции — метод стохастического моделирования — одним из названий которого также является кригинг, а также метод Винера-Колмогорова. Основная идея данного метода состоит в использовании некоторого Гауссова процесса для интерполяции известных значений по критерию минимизации среднеквадратичного отклонения на основе матрицы ковариации, и также для оптимизации гладкости интерполируемых значений

Часто выделяют тот факт, что метод кригинга удовлетворяет условию наилучшего линейного несмещённого предсказания (BLUP - best linear unbiased prediction). Данный термин был введён для оценки случайных величин в линейных смешанных моделях. Есть близкий, практически эквивалентный термин - "лучшая линейная несмещенная оценка" (BLUE - best linear unbiased estimation) для заданных случайных величин, возникающий как часть известной теоремы Гаусса-Маркова\cite[с.~64]{Rasmussen}. Данная теорема гласит, что обыкновенная оценка наименьших квадратов (OLS - ordinary least squares) имеет наименьшую дисперсию выборки в классе несмещённых оценок, если ошибки линейной регрессионной модели некоррелированны, имеют нулевое математическое ожидание и равные дисперсии. Различие BLUP и BLUE заключается в том, что в случае BLUP подразумевается оценка прогнозирования случайных величин, в случае BLUE, говорят об оценке случайной величины. Данный критерий (BLUP) может не выполняться для других методов описанных выше, например для метода сплайнов. Так как определение флуктуации компонент скоростей, из её физического смысла, подразумевает то, что её математическое ожидание равно 0, подразумевая осреднение как по времени, так и по пространству, автоматически удовлетворяется одно из условий теоремы. Удовлетворение другим условиям теоремы будет рассмотрено далее. 

Метод кригинга, как и спектральный метод, относится к классу недетерминистических методов, то есть стохастических методов. Оба метода не используют в основе какую-то жесткую модель, в большей своей степени, вводя зависимость от некоторого случайного процесса, в предположении, характеризующего некоторый реальный процесс распределения физической величины. Метод кригинга имеет больший упор на удовлетворение пространственной ковариации, так как генерируемая случайная переменная $Z$ описывает разброс вокруг неизвестного неизмеренного значения $z$. 

\section{Математическая модель метода стохастического Гауссова моделирования} \label{sect1_2}
В данной части рассмотрим основы метода кригинга. Как говорилось ранее метод кригинга является интерполяционным методом. Это означает, что перед нами стоит задача интерполировать некоторую функцию $f_i = f(\vec{r_i})$, где $f_i$ — известный набор значений интерполируемой функции в точках $\vec{r_i}$. Проведение интерполяции подразумевает под собой нахождение функции $F$ по определению:
\begin{equation}
  \label{eq:kriging_equation1}
  \overline{f}(\vec{r}) = F(\vec{r}, \{f_i\}, \{\vec{r_i}\}),
\end{equation}
\noindent
где $\overline{f}(\vec{r})$ — значение проинтерполированной функции в точке пространства с радиус-вектором $\vec{r}$, $F$ - функция интерполятор, определяющая правило интерполяции известных значений, ${f_i}$ - набор известных значений, ${\vec{r_i}}$ - точки в которых определены эти значения. Как видно из вводимого определения интерполятор $F$ зависит от $2N + 1$ значений, где $N$ — число известных значений. На $F$ накладывается естественное условие точного совпадения значений в известных точках, или
\begin{equation}
  \label{eq:kriging_equation2}
  \overline{f}_j =  F(\vec{r}_j, \{f_i\}, \{\vec{r_i}\})
\end{equation}

В формуле \eqref{eq:kriging_equation2}: $\overline{f}_j = \overline{f}(\vec{r_j})$ и $j = \overline{1..N}$, что представляет собой $N$ условий налагаемых на функцию $F$.

В общем случае, вид функции $F$ не известен, поэтому необходимо применить упрощения. Например, на порядок членов входящих в эту функцию. Наиболее часто встречаемый вид — это линейная зависимость. Как упоминалось выше, кригинг — линейный метод, поэтому применительно к нашему случаю мы будем строить интерполятор вида:
\begin{equation}
  \label{eq:kriging_equation3}
  \overline{f} =  \sum_{i} f_i w_i(\vec{r}),
\end{equation}
\noindent
где $f_i = f(\vec{r_i})$ — уже ранее упомянутые известные значения функции, $w_i(\vec{r})$ - веса привязанные к значениям $f_i$.

Стоит отметить, что в более общей формулировке мы имеем:
\begin{equation}
  \label{eq:kriging_equation4}
  \overline{f}(\vec{r}) - E(\overline{f}(\vec{r})) =  \sum_{i} w_i(\vec{r}) (f(\vec{r_i}) - E(f(\vec{r_i})))
\end{equation}

Введём общепринятое обозначения для средней величины: $m(\vec{r}) = E(\overline{f}(\vec{r}))$ и $m(\vec{r_i}) = E(f(\vec{r_i})))$, тогда:
\begin{equation}
  \label{eq:kriging_equation4_1}
  \overline{f}(\vec{r}) - m(\vec{r}) =  \sum_{i} w_i(\vec{r}) (f(\vec{r_i}) - m(\vec{r_i}))
\end{equation}

Здесь $\overline{f}(\vec{r})$ — оценка значения неизвестной функции $f(\vec{r})$
По сравнению с \eqref{eq:kriging_equation3} учитывается, что математическое ожидание для $\overline{f}(\vec{r})$ и для $f_i$ могут быть не равны нулю. Но даже в таком случае обычно представляют функцию в виде $g(\vec{r}) = m(\vec{r}) + \xi(\vec{r})$, где $m(\vec{r})$ — среднее трендовое значение, $\xi(\vec{r})$ - случайная составляющая, таким образом приходя к уравнению \eqref{eq:kriging_equation3}. Здесь предполагается что $\xi(\vec{r})$ такая, что $E(\xi(\vec{r})) \equiv 0$, также стоит отметить что в таком случае: $E(g(\vec{r})) = m(\vec{r})$, то-есть среднее искомой функции есть трендовое значение.

Рассмотрим значение ошибки получаемое в случае использования \eqref{eq:kriging_equation4}:
\begin{equation}
  \label{eq:kriging_equation5}
  R(\vec{r}) = \overline{f}(\vec{r}) - f(\vec{r})
\end{equation}

Как говорилось ранее метод удовлетворяет условию BLUE - условие не смещённости оценки, то-есть $E(r) = 0$. Это можно показать прямой подстановкой:
\begin{align}
      E(R(\vec{r})) = E(\overline{f}(\vec{r}) - f(\vec{r})) = E(\overline{f}(\vec{r})) - E(f(\vec{r})) \nonumber \\
      = E(m(\vec{r}) +  \sum_{i} w_i(\vec{r}) (f(\vec{r_i}) - m(\vec{r_i})) - m(\vec{r}) = 0
\end{align}

Слагаемые отвечающие за математическое ожидание взаимоуничтожаются по определениям введённым выше, слагаемые внутри суммы также взаимоуничтожаются, что в конечном итоге приводит к нулевому математическому ожиданию оценки ошибки.Таким образом мы удовлетворили одному из пунктов теоремы Гаусса-Маркова строго. Далее приведём доказательство удовлетворению остальным пунктам теоремы.

Необходимо доказать, что построенный таким образом метод имеет наименьшую дисперсию в классе несмещённых оценок

Далее введём в рассмотрение функцию пространственной ковариации:
\begin{equation}
  \label{eq:kriging_equation6}
  Cov(\xi(\vec{r}), \xi(\vec{r} + \vec{h})) = C_{\xi}(\vec{h})
  = E((\xi(\vec{r}) - E(\xi(\vec{r}))) \cdot (\xi(\vec{r} + \vec{h}) - E(\xi(\vec{r} + \vec{h}))))
\end{equation}

Данная функция нужна нам для внесения самосогласованности в метод. При рассмотрении формулы \eqref{eq:kriging_equation3} можно заметить, что нет зависимости между соседними точками. Из-за этого возникает сильное изменение решения при появлении дополнительных точек. Но, если до этого момента не было необходимости рассматривать решение систем алгебраических уравнений, так как не присутствовало связанности между соседними узлами, то теперь внесём её за счёт учета некоторого расстояния между точками.
\begin{equation}
  \label{eq:kriging_equation7}
  \overline{f}(\vec r) = \sum_i \lambda_i \Omega(\vec r - \vec r_i).
\end{equation}
Здесь $\lambda_i$ -- некоторый весовые коэффициенты, которые необходимо будет подобрать в ходе решения, $\Omega(\vec r - \vec r_i)$ -- базисная функция монотонно убывающая с увеличением расстояния между точками. Как и ранее для известных значений мы должны получать тождество.
\begin{equation}
  \label{eq:kriging_equation8}
  \overline{f}_k = \sum_i \lambda_i \Omega(\vec r_k - \vec r_i)
\end{equation}

В итоге имеется система линейных уравнений для вычисления весовых коэффициентов $\lambda$. В матричном виде:
\begin{equation}
  \label{eq:kriging_equation9}
  \overline{F} = \Omega \cdot \Lambda 
\end{equation}

Решением будет являться:
\begin{equation}
  \label{eq:kriging_equation10}
  \Lambda = \Omega^{-1} \overline{F}
\end{equation}

Если подставить \eqref{eq:kriging_equation10} в \eqref{eq:kriging_equation8} можно избавиться от параметра $\lambda$.
\begin{equation}
  \overline{f}(\vec r) = \sum_i f_i \cdot \sum_n \left[ \Omega^{-1}_{in} \cdot \omega(\vec r_n - \vec r) \right] 
\end{equation}
Требование к выполнению условия, что в известных точках получаются точные известные значения, также выполняется. 
\begin{equation}
  \overline{f}(\vec r_i) = \sum_i f_i \cdot \sum_n \left[ \Omega^{-1}_{in} \cdot \omega(\vec r_n - \vec r_i) \right] = f_i 
\end{equation}


\section{Метод кокригинга для генерации флуктуаций скоростей} \label{sect1_3}

Метод кригинга изначально не учитывает возможные дополнительные корреляции с другими величинами. Это может сыграть роль для уточнения данных, так как зачастую при проведении физических экспериментов или измерений, измеряют сразу несколько величин. Так как кригинг наиболее часто используется в геологическом моделировании наиболее простым примером является измерение пористости и проницаемости или некоторого другого набора параметров. Так мы можем дополнить модель использую ковариации между измеряемыми величинами, до этого момента мы рассматривали лишь ковариацию случайной величины сама с собой. Ковариация двух случайных величин представляется в виде:

\begin{equation}
  \label{eq:kriging_equation11}
  cov(\xi, \zeta) = \frac{1}{N} \sum_{n = 1}^N (\xi_n - \overline{\xi}) * (\zeta_n - \overline{\zeta})
\end{equation}

По аналогии с обычным методом кригинга, дополним модель дополнительным учётом зависимости между переменными. Оценим функцию $z$ в окрестности точки $\vec r_0$.  

\begin{equation}
  \label{eq:kriging_equation12}
  \overline{z_{\alpha_0}} (\vec r_0) = \sum_{\alpha = 1}^K \sum_{i = 1}^{n_\alpha} \lambda_{i}^{\alpha} z_{\alpha}(\vec r_i),
\end{equation}
здесь $\overline{z_{\alpha_0}} (\vec r_0)$ -- оценка в виде линейной комбинации различных переменных в окрестности точки $\vec r_0$, $\lambda_{i}^{\alpha}$ -- весовые коэффициенты. Как и обычный кригинг, кокригинг также должен удовлетворять условию несмещённости для построенной оценки \eqref{eq:kriging_equation12}.

\begin{align}
    & E \left\{ \overline{z_{\alpha_0}} (\vec r_0) - z_{\alpha_0} (\vec r_0) \right\} = E \left\{ \sum_{\alpha = 1, \alpha \neq \alpha_0}^K \sum_{i = 1}^{n_\alpha} \lambda_{i}^{\alpha} z_{\alpha}(\vec r_i) + \sum_{i = 1}^{n_{\alpha_0}} \lambda_i^{\alpha_0} z_{\alpha_0} (\vec r_i) - z_{\alpha_0} (\vec r_0) \right\} \nonumber \\
    & = \sum_{\alpha = 1, \alpha \neq \alpha_0} ^ K \left( m_\alpha \sum_{i = 1}^{n_{\alpha_0}} \lambda_i^\alpha \right)
    + m_{\alpha_0} \left( \sum_{i = 1}^{n_{\alpha_0}} \lambda_i^{\alpha_0} - 1 \right) = 0
\end{align}

Также дополним условие \eqref{eq:kriging_equation2}, веса должны быть подобраны таким образом, чтобы при основной переменной с индексом $\alpha_0$ были равны $1$, при любых других переменных, не соответствующих основной, коэффициенты должны быть равны нулю, то есть:
\begin{equation}
    \label{eq:kriging_equation13}
    \sum_{i = 1}^{n_\alpha} \lambda_i^{\alpha} = \delta_{\alpha \alpha_0}
\end{equation}
При учёте ограничивающих выражений \eqref{eq:kriging_equation13}, получаем следующую систему уравнений для \textit{обычного} кокригинга:
\[ 
\left\{
  \begin{array}{rl}
  \label{eq:kriging_equation13_2}
	&\sum_{\beta=1}^K \sum_{j = 1}^{n_{\beta i}} \lambda_j^{\beta} \gamma_{\alpha \beta}(\vec r_i - \vec r_j) + \mu_i = \gamma_{\alpha \alpha_0}(\vec r_i - \vec r_{i0}), \alpha = 1, ..., K, i = 1,...,n_\alpha \\
	&\sum_{i = 1}^{n_\alpha} \lambda_i^{\alpha} = \delta_{\alpha \alpha_0}, \alpha = 1, ..., K, i = 1,...,n_\alpha
  \end{array}
\right.
\]

Таким образом используя систему \ref{eq:kriging_equation13_2} мы можем построить поле случайной величины удовлетворяющей некоторой заданной функции ковариаций. В качестве опорных точек для генерации можно взять, например, последовательность нормально распределённых чисел. Это не будет противоречить постановке задачи кригинга из-за в целом построения случайного процесса и в то же время внесёт дополнительную либо случайную составляющую, либо мы можем взять значения с некоторого поля и решить задачу аппроксимации кригингом для неё. 

Задача кригинга и кокригинга требует в качестве входных данных либо аналитически заданную функцию ковариаций, либо её сеточную аппроксимацию. Основная проблема в том, чтобы каким-то образом перейти от энергетического спектра к ковариационной функции. Следуя из определения для энергетического спектра \cite{pope2000turbulent} можно обратными преобразованиями перейти  к ковариационной функции:

\begin{equation}
    \label{eq:kriging_equation14}
    \Phi_{ij}(\vec{k}) = \frac{1}{(2 \pi)^3} \iiint_{-\infty}^{\infty} R_{ij}(\vec{r}) \exp{(- i \vec{k} \cdot \vec{r})} d\vec{r}.
\end{equation}

\begin{equation}
    \label{eq:kriging_equation14_2}
    R_{ij}(\vec{r}) = \iiint_{-\infty}^{\infty}  \Phi_{ij}(\vec{\vec k}) \exp{(i \vec k \cdot \vec r)} d \vec k.
\end{equation}

Функция ковариаций и тензор спектра скоростей связаны через преобразование Фурье. В связи с этим на функцию $\Phi$ накладываются некоторые ограничения связанные с определением функций ковариации. Так, компоненты этого тензора с $i=j$ должны быть вещественными, то-есть $\Phi_{ii}(\vec k) = \Phi_{ii}^{*}(\vec k)$. Также помимо этого в силу определения преобразования Фурье, компоненты тензора должны быть симметричными, то-есть $\Phi_{ij}(\vec k)=\Phi_{ji}^{*}(\vec k)=\Phi_{ji}(-\vec k)$. Это также требует точной симметрии функции компонент тензора ковариаций, дабы удовлетворить сказанному выше условия вещественности его значений. 

Энергетический спектр турбулентности выражается через диагональные компоненты тензора спектра скоростей следующей зависимостью:
\begin{equation}
    \label{eq:kriging_equation15}
    E(k) = \oint \frac{1}{2} \Phi_{ii}(\vec k) d \Omega (k).
\end{equation}

В данном случае переход от энергетического спектра к тензору не является явным и требует дополнительных предположений и условий. Переход от $\Phi_{ij}(\vec k)$ можно осуществить численным интегрированием, либо при наличии функции $E(k)=F(\Phi_{ij}(\vec k))$ осуществив обратное разрешение относительно компонент тензора.

В конечном итоге, имеем алгоритм основными этапами которого является:
\begin{enumerate}
    \item Построить тензор $\Phi_{ij}$ по заданной функции $E(k)$;
    \item Перейти от тензора $\Phi_{ij}$ к тензору ковариаций $R_{ij}$;
    \item Построить матрицу ковариаций на основе полученного тензора спектра скоростей $\Phi_{ij}$;
    \item Найти собственные значения и собственные вектора полученной матрицы ковариаций;
    \item Построить поле скоростей базируясь на сгенерированной последовательности чисел и на полученных собственных значениях и векторах.
\end{enumerate}

Наиболее длительным и затратным по вычислительным ресурсам и времени является процесс нахождения собственных чисел и векторов матрицы ковариаций. В среднем вычислительная сложность алгоритмов как итерационных, так и точных составляет $O(N^2)$. Если не использовать приемы для разряжения этой матрицы понадобится хранить $3 \cdot N^3$, где $N$ -- число узлов в сетке вычислительной области, не считая данных для сборки это глобальной матрицы. Но стоит отметить, что сама процедура генерации является очень простой и происходит быстро, так как нам необходимо всего лишь просуммировать полученные значения. Если решить задачу один раз и сохранить полученные собственные вектора и числа можно достаточно эффективно генерировать турбулентные поля скоростей.

Для осуществления матричных преобразований используется библиотека "Armadillo" предоставляющая $C++$ API для работы с различными типами матриц, а также алгоритмов связанных с ними, например нахождение собственных чисел и значений для матриц \cite{sanderson2016armadillo, sanderson2018user}. Помимо этого, библиотека также имеет функционал для генерации не только обычных последовательной случайных чисел, но также и коррелированных например по многомерному нормальному распределению.

\section{Метод последовательных симуляций} \label{sect1_4}

Можно значительно ускорить описанный выше метод если использовать метод последовательного моделирования Гаусса. В общем, можно охарактеризовать метод последовательного моделирования, как разбиения рассматриваемой области на подобласти и проведение в ней стохастического моделирования. Основной сложностью является возникающие поверхности разделения на подобласти, необходимо учесть это, что бы не получать разрывы функций на этих поверхностях. 

Как и в рассматриваемых не последовательных процедурах, в случае последовательного моделирования так же рассматривается набор точек $\vec p_i$, для которых известных значения $v_i$. Требуется рассчитать значение в некоторой точке $\vec q_i$ при задаваемой пространственной ковариации $C(\vec h)$ и среднем значении $\langle v \rangle$, в нашем случае, из физического смысла флуктуаций, задача упрощается, так как $\langle v' \rangle=0$. Так же используя процедуру кригинга приходим к задаче:
\begin{equation}
    \label{eq:kriging_seq_1}
    \hat{A} \vec x = \vec b
\end{equation}
\begin{equation}
    \label{eq:kriging_seq_2}
    A_{ij} = C(\vec p_i - \vec q_i)
\end{equation}
\begin{equation}
    \label{eq:kriging_seq_3}
    b_i = C(\vec p_i - \vec q)
\end{equation}

Как и в обычном подходе, СЛАУ также учитывает точное совпадение значений $v_i$ в точках $p_i$. Из постановки выше следует что $E(u) = \sum_{i} x_i \cdot v_i + \langle v \rangle$, причём $\langle v \rangle$ - заданный параметр, и $Cov(v) = \sum_{i} x_i \cdot b_i + C(0)$, где $C(0)$ -- также известный задаваемый параметр.

Как говорилось выше, вычислительная область подразделяется на подобласти. Так как расчёт ведётся на сетке, мы можем рассматривать не подобласть, а набор ближайших соседей узлов на сетке, тем самым, вводя новый параметр $N$ -- число ближайших соседей к рассматриваемой точке.

Так процедура последовательного моделирования может быть представлена в виде следующих шагов: 

\begin{enumerate}
    \item Выбирается случайная точка на сетке;
    \item Ищется $N$ ближайших к ней соседей с уже посчитанными значениями среднего и ковариации;
    \item Строим матрицу $N \times N$ и решаем СЛАУ по методу описанному ранее методу, рассчитываем среднее и ковариацию в этой точке;
    \item Зная среднее и ковариацию генерируем случайное число из Гауссова распределения $\mathcal{N}(E(v), Cov(u))$;
    \item Добавляем значение в массив известных.
\end{enumerate}

Процедура может несколько отличаться для случаев если $v$ -- является вектором. В данном случае мы можем рассматривать два пути решения этой проблемы. Первый из них, не видоизменять алгоритм, работать с векторными и матричными величинами, в итоге среднее и ковариация являются вектором и матрицей соответственно. Окончательное значение для этих параметров находится из стохастического моделирования. Второй подход заключается в учёте каждой точки столько раз, сколько значений в векторе $v$, так например для поля флуктуаций у которого в каждой точке по 3 компоненты имеется по 3 одинаковые точки с различными значениями.
